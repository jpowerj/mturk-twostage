import datetime
import os

import pandas as pd
import boto3
import pytz
import joblib
import xmltodict
import numpy as np
rng = np.random.default_rng()

### Global params ###

# The list of wages randomly sampled from when generating wage for each HIT
wage_dist = ['0.50','0.90','0.95','0.98','0.99',
            '1.00',
            '1.01','1.02','1.05','1.10','1.50']

# The number of stage-1 HITs to launch (and so, also the number of stage-2 HITs that
# will be created)
num_hits = 1000

### Global constants ###

# The qual id for the participation qual
participant_qual_id = "303SJT1CWE5D23ZEJCT5ZGDLM1P4FN"

# Date cutoff: any hits before this date won't get downloaded by download_all_hits()
date_cutoff = datetime.datetime(2021,10,30,0,0,0,0,pytz.UTC)

# fpath for the list of workers who submitted stage 1. Generated by 01_MonitorStage1
stage1_submit_list_fpath = os.path.join("..","results_2stage","stage1_submit_list.pkl")
# fpath for the .csv containing the *results* of the stage 1 HIT (as in, including
# their responses to the 3 demographic questions)
stage1_results_fpath = os.path.join("..","results_2stage","stage1_results.csv")
# fpath for the .csv where each row is a launched stage 2 HIT
stage2_launched_fpath = os.path.join("..","results_2stage","stage2_launched_workers.csv")
# fpath for the .pkl containing the list of workers who *submitted* their custom
# stage 2 HIT
stage2_submitted_fpath = os.path.join("..","results_2stage","stage2_submitted_workers.pkl")

### Global functions ###

# Before connecting to MTurk, set up your AWS account and IAM settings as
# described here:
# https://blog.mturk.com/how-to-use-iam-to-control-api-access-to-your-mturk-account-76fe2c2e66e2
#
# Follow AWS best practices for setting up credentials here:
# http://boto3.readthedocs.io/en/latest/guide/configuration.html

# Use the Amazon Mechanical Turk Sandbox to publish test Human Intelligence
# Tasks (HITs) without paying any money.  Sign up for a Sandbox account at
# https://requestersandbox.mturk.com/ with the same credentials as your main
# MTurk account.

def assign_qual_safe(client, worker_id, qual_id, qual_num=0, notify=False):
    """
    Assigns the qualification "safely", meaning that it just returns without
    doing anything if the worker already has the qual
    """
    try:
        response = client.get_qualification_score(
            QualificationTypeId=qual_id,
            WorkerId=worker_id
        )
        # If we're here, that means the worker already has the qual. So we don't
        # do anything
        return f"Worker {worker_id} already has qual {qual_id}"
    except client.exceptions.RequestError as e:
        # If we're here, that means the worker does *not* have the qual.
        # So assign it
        #print(e)
        # Assign this worker the participant qual
        response = client.associate_qualification_with_worker(
            QualificationTypeId=qual_id,
            WorkerId=worker_id,
            IntegerValue=qual_num,
            SendNotification=notify
        )
        return f"Worker {worker_id} successfully given qual {qual_id}"

def create_new_qual(client, new_qual_name):
    response = client.create_qualification_type(
        Name=new_qual_name,
        Keywords='workplace,survey,custom',
        Description='Participation in the Columbia TextLab workplace survey',
        QualificationTypeStatus='Active'
    )
    # Get the new qual info (as opposed to the request metadata)
    qual_info = response['QualificationType']
    # Extract the info we need
    qual_name = qual_info['Name']
    qual_id = qual_info['QualificationTypeId']
    #qual_creation = qual_info['CreationTime']
    return qual_name, qual_id

# OLD VERSION
def create_new_qual_old():
    qual_list = get_current_quals()
    custom_quals = [n for n in qual_list if "Workplace_Survey_Custom" in n['Name']]
    # Now find the one with the highest number
    most_recent_suffix = "om"
    for cur_qual in custom_quals:
        qual_num = cur_qual['Name'][-2:]
        print(qual_num)
        if most_recent_suffix == "om":
            # Just replace it, we know it's newer since "om" was the very first
            most_recent_suffix = cur_qual['Name'][-2:]
        else:
            # TODO: Check if the number for this qual is higher than the num for most_recent
            most_recent_suffix = cur_qual['Name'][-2:]
    # Now add 1 to the suffix to get the new qual name
    if most_recent_suffix == "om":
        new_suffix = "01"
    else:
        old_suffix_num = int(most_recent_suffix)
        new_suffix_num = old_suffix_num + 1
        new_suffix = str(new_suffix_num).zfill(2)
    new_qual_name = "Workplace_Survey_Custom" + new_suffix
    # And create it
    response = client.create_qualification_type(
        Name=new_qual_name,
        Keywords='workplace,survey,custom',
        Description='Participation in the Columbia TextLab workplace survey',
        QualificationTypeStatus='Active'
    )
    return new_qual_name, response

def download_all_hits(client, start_cutoff=date_cutoff, end_cutoff=None,
                      save_to_file=True):
    """
    Sets end_cutoff to be (localized) datetime.datetime.now() if None
    """
    if end_cutoff is None:
        end_cutoff = localize_datetime(datetime.datetime.now())
    download_fpath = "../results_2stage/all_hit_data.pkl"
    print(f"Downloading list of hits from {start_cutoff} to {end_cutoff} (to {download_fpath})")
    all_hit_data = []
    all_scraped = False
    cur_next_token = None
    while not all_scraped:
        # This returns 'NextToken', 'NumResults', and 'HITs'
        if cur_next_token is None:
            response = client.list_hits(
                #NextToken='string',
                MaxResults=100
            )
        else:
            response = client.list_hits(
                NextToken=cur_next_token,
                MaxResults=100
            )
        if 'NextToken' in response:
            cur_next_token = response['NextToken']
            print(cur_next_token)
        else:
            # No next token, so we're at the final page
            all_scraped = True
        # We can stop if creation time is before August
        all_hits = response['HITs']
        if len(all_hits) > 0:
            # Loop through them, stopping if we hit one with creationtime outside
            # the cutoff
            for cur_hit in all_hits:
                creation = cur_hit['CreationTime']
                try:
                    creation_before_cutoff = creation < start_cutoff
                except TypeError as e:
                    # Need to localize the cutoff
                    start_cutoff = localize_datetime(start_cutoff)
                if creation < start_cutoff:
                    print(f"Creation {creation} before start_cutoff")
                    # This means we've gotten them all, since they download
                    # in reverse chronological order
                    all_scraped = True
                    break
                try:
                    creation_after_cutoff = creation > end_cutoff
                except TypeError as e:
                    end_cutoff = localize_datetime(end_cutoff)
                if creation > end_cutoff:
                    #print(f"Creation {creation} after end_cutoff")
                    # This means we just skip this one, but have to
                    # keep going
                    continue
                else:
                    all_hit_data.append(cur_hit)
        else:
            all_scraped = True
    if save_to_file:
        joblib.dump(all_hit_data, download_fpath)
    return all_hit_data

default_keys_fpath = "../../IndependentStudyWithJeff/aws/accessKeys.csv"
def gen_client(keys_fpath=default_keys_fpath):
    # By default, HITs are created in the free-to-use Sandbox
    create_hits_in_live = True

    environments = {
            "live": {
                "endpoint": "https://mturk-requester.us-east-1.amazonaws.com",
                "preview": "https://www.mturk.com/mturk/preview",
                "manage": "https://requester.mturk.com/mturk/manageHITs",
                "reward": "0.10"
            },
            "sandbox": {
                "endpoint": "https://mturk-requester-sandbox.us-east-1.amazonaws.com",
                "preview": "https://workersandbox.mturk.com/mturk/preview",
                "manage": "https://requestersandbox.mturk.com/mturk/manageHITs",
                "reward": "0.11"
            },
    }
    mturk_environment = environments["live"] if create_hits_in_live else environments["sandbox"]

    # Load access+secret keys
    api_keys = pd.read_csv(keys_fpath)
    key_entry = api_keys.iloc[0]
    access_id = key_entry['Access key ID']
    secret_id = key_entry['Secret access key']

    session = boto3.Session()
    client = session.client(
        service_name='mturk',
        region_name='us-east-1',
        # dev endpoint
        #endpoint_url="https://mturk-requester.us-east-1.amazonaws.com",
        # sandbox endpoint
        #endpoint_url="https://mturk-requester-sandbox.us-east-1.amazonaws.com",
        endpoint_url = mturk_environment['endpoint'],
        aws_access_key_id=access_id,
        aws_secret_access_key=secret_id,
    )
    
    # Test that you can connect to the API by checking your account balance
    user_balance = client.get_account_balance()

    # In Sandbox this always returns $10,000. In live, it will be your acutal balance.
    print("Your account balance is {}".format(user_balance['AvailableBalance']))
    
    return client, mturk_environment

def get_all_quals(client):
    """
    For when we reach the limit of 100 numbers per qual (0-99), so need to create
    a new qualification that we can assign. The syntax is:
    
    response = client.create_qualification_type(
        Name='string',
        Keywords='string',
        Description='string',
        QualificationTypeStatus='Active'|'Inactive',
        RetryDelayInSeconds=123,
        Test='string',
        AnswerKey='string',
        TestDurationInSeconds=123,
        AutoGranted=True|False,
        AutoGrantedValue=123
    )
    
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/mturk.html#MTurk.Client.create_qualification_type
    
    and for listing the existing types:
    response = client.list_qualification_types(
        Query='string',
        MustBeRequestable=True|False,
        MustBeOwnedByCaller=True|False,
        NextToken='string',
        MaxResults=123
    )
    
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/mturk.html#MTurk.Client.list_qualification_types
    """
    qual_response = client.list_qualification_types(
        MustBeRequestable=False,
        MustBeOwnedByCaller=True,
        MaxResults=100
    )
    # The actual list is in 'QualificationTypes'
    qual_list = qual_response['QualificationTypes']
    return qual_list

def get_current_qual():
    with open("../results_2stage/current_qual.txt", 'r', encoding='utf-8') as f:
        qual_info = f.read()
    qual_elts = qual_info.strip().split(",")
    # First is qual name, second is qual id, third is qual_num of the last launched HIT,
    # fourth is last offer_amt
    qual_name = qual_elts[0]
    qual_id = qual_elts[1]
    last_qual_num = int(qual_elts[2])
    last_offer_amt = qual_elts[3]
    return {'qual_name': qual_name, 'qual_id': qual_id,
            'last_qual_num': last_qual_num, 'last_offer_amt': last_offer_amt}

def get_hit_for_worker(all_hits, worker_id, verbose=False):
    vprint = print if verbose else lambda x: None
    # The HIT only has the worker_id in its title, so we have to extract
    # using mtglobals.worker_id_from_title()
    #vprint([h['Title'] for h in all_hits])
    results = [h for h in all_hits if worker_id_from_title(h['Title']) == worker_id]
    if len(results) == 0:
        raise Exception(f"No HIT found for worker {worker_id}")
    return results[0]

def get_hit_submissions(client, hit_id):
    all_submissions = []
    all_scraped = False
    # Start with a single call
    response = client.list_assignments_for_hit(HITId=hit_id)
    all_submissions.extend(response['Assignments'])
    if 'NextToken' in response:
        cur_next_token = response['NextToken']
        #cur_num_results = response['NumResults']
        while not all_scraped:
            response = client.list_assignments_for_hit(HITId=hit_id, NextToken=cur_next_token)
            cur_submissions = response['Assignments']
            all_submissions.extend(cur_submissions)
            if 'NextToken' in response:
                cur_next_token = response['NextToken']
            else:
                all_scraped = True
    return all_submissions

def get_qual_id(client, qual_name):
    all_quals = get_all_quals(client)
    matching_quals = [info for info in all_quals if info['Name'] == qual_name]
    if len(matching_quals) == 0:
        raise Exception("No matching quals found!")
    else:
        qual_info = matching_quals[0]
    qual_id = qual_info['QualificationTypeId']
    return qual_id

def get_workers_with_qual(client, qual_name):
    # First get the id for this qual
    qual_id = get_qual_id(client, qual_name)
    all_quals = []
    all_worker_ids = []
    cur_next_token = None
    response = client.list_workers_with_qualification_type(
        QualificationTypeId=qual_id,
        Status='Granted',
        MaxResults=100,
    )
    cur_quals = response['Qualifications']
    cur_worker_ids = [q['WorkerId'] for q in cur_quals]
    all_worker_ids.extend(cur_worker_ids)
    all_quals.extend(cur_quals)
    all_quals.extend(response['Qualifications'])
    while 'NextToken' in response:
        cur_next_token = response['NextToken']
        response = client.list_workers_with_qualification_type(
            QualificationTypeId=qual_id,
            Status='Granted',
            MaxResults=100,
            NextToken=cur_next_token
        )
        cur_quals = response['Qualifications']
        cur_worker_ids = [q['WorkerId'] for q in cur_quals]
        all_worker_ids.extend(cur_worker_ids)
        all_quals.extend(cur_quals)
    return all_worker_ids

pacific = pytz.timezone('US/Pacific')
def localize_datetime(dt_obj):
    """
    Uses pytz to just put the time into Pacific timezone
    """
    return dt_obj.replace(tzinfo=pacific)

def parse_stage1_answer(answer_xml):
    parse_result = xmltodict.parse(answer_xml)
    answer_data = parse_result['QuestionFormAnswers']
    answers = answer_data['Answer']
    answer_dict = {d['QuestionIdentifier']: d['FreeText'] for d in answers}
    # But make sure that empty responses just get the empty string
    for qid in ['age','onlinehrs','reason']:
        if qid not in answer_dict:
            answer_dict[qid] = ''
    return answer_dict

def qual_exists(client, qual_name):
    all_quals = get_all_quals(client)
    matching_quals = [info for info in all_quals if info['Name'] == qual_name]
    if len(matching_quals) == 0:
        return False
    return True

def random_wage():
    """
    Draws an element, uniformly at random, from the global var wage_dist 
    """
    return rng.choice(wage_dist)

def update_current_qual(new_qual_name, new_qual_id, new_qual_num, new_offer_amt):
    info_str = f"{new_qual_name},{new_qual_id},{new_qual_num},{new_offer_amt}"
    with open('../results_2stage/current_qual.txt', 'w', encoding='utf-8') as g:
        g.write(info_str)
    print(f"Current qual updated to be: {info_str}")
        
def worker_id_from_title(hit_title):
    title_elts = hit_title.split(" ")
    worker_id = title_elts[-1]
    return worker_id

def write_log(msg):
    stamp = datetime.datetime.now().isoformat()
    with open('mt_log.txt', 'a', encoding='utf-8') as outfile:
        outfile.write(f"[{stamp}] {msg}\n")
